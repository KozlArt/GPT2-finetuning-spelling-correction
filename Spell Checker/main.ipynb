{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "cellId": "55n95886arms4887dtsv2m",
    "id": "qdBgieNv1OrJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, random\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments, AutoModelWithLMHead\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import set_seed\n",
    "import sys\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "cellId": "i5vueu250gbg8zr01j8crt"
   },
   "outputs": [],
   "source": [
    "SEED = 314\n",
    "set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "cellId": "0absiovy6owbp5dlyjg15m",
    "id": "ZkJg7clu1OrN"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "cellId": "3rqgmtaw1aldu011ez3gsv",
    "id": "TQgM4XXl1OrP"
   },
   "outputs": [],
   "source": [
    "class spell:\n",
    "    def __init__(self, data, corrupted_text, correct_text):\n",
    "        print(\"starting\")\n",
    "        words = \" \".join(list(data[correct_text])).lower()\n",
    "        print(\"extracting tokens\")\n",
    "        words = re.findall(r'[\\w]+', words)\n",
    "        #words = u\" \".join(words).split()\n",
    "        print(\"creating set of syms\")\n",
    "        self.d_sym = \"\".join(list(set(list(\"\".join(words)))))\n",
    "        print(\"creating set of words\")\n",
    "        self.d_set = set(words)\n",
    "        print(\"creating dict\")\n",
    "        self.d_dict = dict(Counter(words))\n",
    "        print(\"init done\")\n",
    "        print(\"\")\n",
    "    \n",
    "    def create_symspell(self, arr):\n",
    "        self.pbar = tqdm(total=len(arr))\n",
    "        self.symdict = defaultdict(list)\n",
    "        pool = ThreadPool(10)\n",
    "        pool.map(self.symspell, arr[:10000])\n",
    "    \n",
    "    def symspell(self, word):\n",
    "        words = self.away_2(word)\n",
    "        for w in words:\n",
    "            self.symdict[w].append(word)\n",
    "        self.pbar.update(1)\n",
    "            \n",
    "    def away_1(self, word):\n",
    "        #letters = self.d_sym\n",
    "        letters = 'абвгдежзийклмнопрстуфхцчшщъыьэюяё'\n",
    "        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "        #deletes = [L + R[1:] for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "        replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
    "        inserts = [L + c + R for L, R in splits for c in letters]\n",
    "        return set(transposes + replaces + inserts) #deletes\n",
    "\n",
    "    def away_2(self, word):\n",
    "        return set([e2 for e1 in self.away_1(word)\n",
    "                    for e2 in self.away_1(e1)])\n",
    "    \n",
    "    def known(self, words):\n",
    "        return set(w for w in words if w in self.d_set)\n",
    "\n",
    "    def edit_candidates(self, word):\n",
    "        ttt = self.known(self.away_1(word)) | self.known(self.away_2(word))\n",
    "\n",
    "        return list(ttt)\n",
    "\n",
    "    def most_freq_edits(self, word):\n",
    "        lst = self.edit_candidates(word)\n",
    "        lst.sort(key=lambda x: self.d_dict[x])\n",
    "        lst.reverse()\n",
    "        return lst\n",
    "\n",
    "    def token(self, sent):\n",
    "        return re.findall(r'[\\w]+', sent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "cellId": "hbwml1fyr3c2xyffjve9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RMFaZhJW1OrU",
    "outputId": "fd64c84c-f280-4753-c30e-c19bee62e87b",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "extracting tokens\n",
      "creating set of syms\n",
      "creating set of words\n",
      "creating dict\n",
      "init done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = spell(data, \"corrupted_text\", \"correct_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "cellId": "8s1l8tj94k71xn4h3ednb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['человек',\n",
       " 'человека',\n",
       " 'человеку',\n",
       " 'человеке',\n",
       " 'человеко',\n",
       " 'мелочен',\n",
       " 'келовей',\n",
       " 'человечны',\n",
       " 'человке',\n",
       " 'человев',\n",
       " 'человечно',\n",
       " 'мелован',\n",
       " 'человече']"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.most_freq_edits(\"человен\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "oq0cl8vu0bfpgtjiapr0i",
    "execution_id": "f773e159-5158-49e2-9c29-ff8b6f62447f"
   },
   "source": [
    "# fine-tuning gpt-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "cellId": "oe9ft41zlrqqbtynh2hv"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "train_data = data.correct_text.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "cellId": "17wo5m1dvg6iz21cvhvwb7a"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def build_text_files(data_arr, dest_path):\n",
    "    with open(dest_path, 'w') as f:\n",
    "        data = ''\n",
    "        for texts in data_arr:\n",
    "            data += texts + \"  \"\n",
    "        f.write(data)\n",
    "\n",
    "train, test = train_test_split(train_data,test_size=0.1)\n",
    "\n",
    "build_text_files(train,'train_dataset.txt')\n",
    "build_text_files(test,'test_dataset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "cellId": "gbbiaazfnaiir4ejmg8i2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca543b05db640d690ec84fe55e7b3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5f52f03d5540eba5811164b34f498c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1713123.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8befbca8288b40619596dd51fee57382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1270925.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")\n",
    "\n",
    "train_path = 'train_dataset.txt'\n",
    "test_path = 'test_dataset.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "cellId": "jipgbvsnpzsemb5eaapfve"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/data/datasets/language_modeling.py:54: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "def load_dataset(train_path,test_path,tokenizer):\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=128)\n",
    "\n",
    "    test_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=test_path,\n",
    "          block_size=128)\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset,test_dataset,data_collator\n",
    "\n",
    "train_dataset,test_dataset,data_collator = load_dataset(train_path,test_path,tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "cellId": "p83imn2abjouz7sfh5cbud"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/modeling_auto.py:742: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35deded72bb44998884e92f3ec5cb215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=551290714.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-ru\", \n",
    "    overwrite_output_dir=True, \n",
    "    num_train_epochs=1, \n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    eval_steps = 500,\n",
    "    save_steps=1000,\n",
    "    warmup_steps=500,\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "q0f0951pxshb8r9477dfc"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "cellId": "tnags561fjznebup40mia"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./gpt2-ru\n",
      "Configuration saved in ./gpt2-ru/config.json\n",
      "Model weights saved in ./gpt2-ru/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "zpplziro0giiewwfunj7d",
    "execution_id": "163fe576-890b-47a1-858e-aca24bd10537"
   },
   "source": [
    "# Поиск и замена ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "cellId": "falz21hycfh98xta5tdnn"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3dc3c12b02746ed875ef35eb35d3332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1713123.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b815e223cda4f3caeed4c0d930b59a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1270925.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469b9c7ba7124068bddd5e574a1e2bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=608.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!g2.mig\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "with torch.no_grad():\n",
    "    model = GPT2LMHeadModel.from_pretrained('./gpt2-ru') #finetuned rugpt-2\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('sberbank-ai/rugpt3small_based_on_gpt2')\n",
    "\n",
    "def score(sentence):\n",
    "    tokenize_input = tokenizer.encode(sentence)\n",
    "    tensor_input = torch.tensor([tokenize_input]).to(device)\n",
    "    loss = model(tensor_input, labels=tensor_input)[0]\n",
    "    return np.exp(loss.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "cellId": "m27u06me1zh7q1hvt29s4t"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "def find_best(sent, strategy = None, top = 6, att_score = 500, att_freq = 3):\n",
    "    global a\n",
    "    tokenized_lower = a.token(sent.lower())\n",
    "    tokenized_normal = a.token(sent)\n",
    "\n",
    "    # ищем какие слова - ошибки\n",
    "    words_mistakes = {}  # ключ - слово, значение - индекс в tokenized_lower\n",
    "    for i, word in enumerate(tokenized_lower):\n",
    "        if not [word] == list(a.known([word])):\n",
    "            words_mistakes[word] = i\n",
    "    \n",
    "    \n",
    "    # ищем по словарю возможные замены\n",
    "    edit_suggestions = []\n",
    "    words_mistakes_list = []\n",
    "    for word in words_mistakes:\n",
    "        words_mistakes_list.append(word)\n",
    "        edit_suggestion = a.most_freq_edits(word)\n",
    "        if edit_suggestion:\n",
    "          if top is not None:\n",
    "            if len(edit_suggestion) > top:\n",
    "              edit_suggestion = edit_suggestion[:top-1]\n",
    "          edit_suggestions.append(edit_suggestion)\n",
    "        else:\n",
    "            edit_suggestions.append([word])\n",
    "\n",
    "    # генерируем подстановоки вместо ошибок\n",
    "\n",
    "    pairs = list(itertools.product(*edit_suggestions))\n",
    "    sent_suggestions = []\n",
    "    for pair in pairs:\n",
    "        sent_tmp = sent\n",
    "        for i in range(len(words_mistakes)):\n",
    "            if tokenized_normal[words_mistakes[words_mistakes_list[i]]][0].isupper():\n",
    "                replace = pair[i]\n",
    "                replace = replace[0].upper() + replace[1:]\n",
    "            else:\n",
    "                replace = pair[i]\n",
    "            sent_tmp = sent_tmp.replace(tokenized_normal[words_mistakes[words_mistakes_list[i]]], replace)\n",
    "\n",
    "        sent_suggestions.append(sent_tmp)\n",
    "    #sent_suggestions = list(set(sent_suggestions))\n",
    "    #print(len(sent_suggestions))\n",
    "\n",
    "    # проверяем семантическую адекватность подстановок и выбираем лучшую\n",
    "    scores = []\n",
    "    for i in sent_suggestions:\n",
    "        scores.append(score(i))\n",
    "    #plt.hist(scores)\n",
    "    #plt.show()\n",
    "    return sent_suggestions[np.argmin(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "cellId": "60nqrf5bq55yja9wq0thwd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Об этом через минуту.'"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.mig\n",
    "find_best(\"Об этом чернз минуту.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "63pt2448l46336fua35dmh",
    "execution_id": "2d4db47f-533b-43a9-b3fd-bd876a581871",
    "id": "pVyKP5E6WJTC"
   },
   "source": [
    "# Тесты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "58s25z6vifhnzaovh8818",
    "execution_id": "47d15192-9862-4fdf-9112-ad95c67d748a",
    "id": "urWQFC34XTca"
   },
   "source": [
    "## Тест всего билда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "cellId": "csr0alzng5mvmsvdgvqek",
    "id": "BrD-9fpO1OrY"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "def validate(data, verbose = False):\n",
    "  res = []\n",
    "  time1 = time.time()\n",
    "  for i, elm in tqdm(enumerate(data.corrupted_text), total = len(data)):\n",
    "    res.append(find_best(elm))\n",
    "  l = 0\n",
    "  n = 0\n",
    "  time2 = time.time()\n",
    "  for i, elm in enumerate(data.correct_text):\n",
    "    n += 1\n",
    "    if elm == res[i]:\n",
    "      l += 1\n",
    "    else:\n",
    "      if verbose:\n",
    "        print(\"FAILED || \", data.corrupted_text.iloc[i], '==>', res[i], '!!!===', elm)\n",
    "  \n",
    "  print(\"TOTAL ACU: \",l/n)\n",
    "  print(\"SECONDS PER ITER :\", np.round((time2-time1)/len(data), 4))\n",
    "  print(\"TOTAL HOURS FOR ALL PRiVATE: \", np.round((time2-time1)/len(data) * 56000 / (3600),1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "cellId": "m9x47v5peupvb5x4sy4v",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RV5fVgfQMmIz",
    "outputId": "130ebf35-5932-4cc7-8d5c-ba88fd4544f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILED ||  Считает, что ссожет ить вечно! ==> Считает, что сможет быть вечно! !!!=== Считает, что сможет жить вечно!\n",
      "FAILED ||  Вы имеетн в виду силу ьога? ==> Вы имеете в виду силу тогда? !!!=== Вы имеете в виду силу бога?\n",
      "FAILED ||  босаснов зефир ванильный темной глазури ==> боссанова зефир ванильный темной глазури !!!=== БоссаНова зефир ванильный темной глазури\n",
      "FAILED ||  Филир Морис комп Эксперт ==> Филир Морис комп Эксперт !!!=== Филип Морис комп Эксперт\n",
      "FAILED ||  Сегнал заднего хода ==> Сигналы заднего хода !!!=== Сигнал заднего хода\n",
      "FAILED ||  - Во сколько твой ресй в Вашингтон? ==> - Во сколько твой тест в Вашингтон? !!!=== - Во сколько твой рейс в Вашингтон?\n",
      "FAILED ||  я шлубaко взволнован наш с ней встречей. ==> я глубоко взволнован наш с ней встречей. !!!=== я глубоко взволнован нашей с ней встречей.\n",
      "FAILED ||  А ты пока азправ. ==> А ты пока заправь. !!!=== А ты пока заправься.\n",
      "FAILED ||  эт мой боат. Помните, мой пладш брат. ==> эт мой брат. Помните, мой плачу брат. !!!=== Это мой брат. Помните, мой младший брат.\n",
      "FAILED ||  Уходе, ешкин кот! ==> Уходе, ешкин кот! !!!=== Уходи, ешкин кот!\n",
      "FAILED ||  Так она теб нраветсы? ==> Так она теб нравится? !!!=== Так она тебе нравится?\n",
      "FAILED ||  А это не слишком глуп? ==> А это не слишком глуп? !!!=== А это не слишком глупо?\n",
      "FAILED ||  Отвечать только \"да\" ли \"рет\". ==> Отвечать только \"да\" ли \"нет\". !!!=== Отвечать только \"да\" или \"нет\".\n",
      "FAILED ||  - Это тка необычно, но если хоиите... ==> - Это тка необычно, но если хотите... !!!=== - Это так необычно, но если хотите...\n",
      "FAILED ||  Завидуете сране, где есть греои, а? ==> Завидуете драже, где есть гренки, а? !!!=== Завидуете стране, где есть герои, а?\n",
      "FAILED ||  Это руьжя. где оружейный склад? ==> Это ружьё. где оружейный склад? !!!=== Это ружья. Где оружейный склад?\n",
      "FAILED ||  Мре был около десяти лет. ==> Мне был около десяти лет. !!!=== Мне было около десяти лет.\n",
      "FAILED ||  Жебатеоьаня конфета Mentos Мята ==> Жебатеоьаня конфета Mentos Мята !!!=== Жевательная конфета Mentos Мята\n",
      "FAILED ||  Мнп нравятся тво кудряшки. ==> Мне нравятся тво кудряшки. !!!=== Мне нравятся твои кудряшки.\n",
      "FAILED ||  тЭо ыбл страшный кошмаром моей матери. ==> тЭо был страшный кошмаром моей матери. !!!=== Это был страшный кошмаром моей матери.\n",
      "FAILED ||  Напиток марaчн Колозвончик ==> Напиток марион Колозвончик !!!=== Напиток марочный Колозвончик\n",
      "FAILED ||  - он енили его этим утром. ==> - он убили его этим утром. !!!=== - Они сменили его этим утром.\n",
      "FAILED ||  Одни из моих любимых. ==> Одни из моих любимых. !!!=== Один из моих любимых.\n",
      "FAILED ||  Я теб вытащу отсюда. ==> Я теб вытащу отсюда. !!!=== Я тебя вытащу отсюда.\n",
      "FAILED ||  расснаж, где имено он торговал. ==> расскажу, где имено он торговал. !!!=== Расскажи, где именно он торговал.\n",
      "FAILED ||  Ты со иной разговариваешь, урод? ==> Ты со иной разговариваешь, урод? !!!=== Ты со мной разговариваешь, урод?\n",
      "FAILED ||  этт Стивенз тож мастер по части самокатов. ==> что Стивенз тож мастер по части самокатов. !!!=== Мэтт Стивенз тоже мастер по части самокатов.\n",
      "FAILED ||  Ух, ты, вмолько лте, сколько зим. ==> Ух, ты, сколько мне, сколько зим. !!!=== Ух, ты, сколько лет, сколько зим.\n",
      "FAILED ||  мармер Беби спрей назальный ==> картер Беби спрей назальный !!!=== Маример Беби спрей назальный\n",
      "FAILED ||  Я ебя не вжиу. Я тебя не вижу. ==> Я ебя не вижу. Я тебя не вижу. !!!=== Я тебя не вижу. Я тебя не вижу.\n",
      "FAILED ||  - еМня никто никогда не броса. ==> - меня никто никогда не бросил. !!!=== - Меня никто никогда не бросал.\n",
      "FAILED ||  Я бы .того не рекомендовал. ==> Я бы .того не рекомендовал. !!!=== Я бы этого не рекомендовал.\n",
      "FAILED ||  Главное - дрибшихиться на пушечный вчсирел. ==> Главное - дрибшихиться на пушечный выстрел. !!!=== Главное - приблизиться на пушечный выстрел.\n",
      "FAILED ||  Там из-за щжема мнста не было. ==> Там из-за джемка места не было. !!!=== Там из-за джема места не было.\n",
      "FAILED ||  Не щнаю, как ты, а я бы, черт мен дери, выпил. ==> Не знаю, как ты, а я бы, черт мен дери, выпил. !!!=== Не знаю, как ты, а я бы, черт меня дери, выпил.\n",
      "FAILED ||  - Хочель рое-что увидеть? - Думаю, нет. ==> - Форель рое-что увидеть? - Думаю, нет. !!!=== - Хочешь кое-что увидеть? - Думаю, нет.\n",
      "FAILED ||  А где, черт возьми, вве коны? ==> А где, черт возьми, все кофе? !!!=== А где, черт возьми, все копы?\n",
      "FAILED ||  Можте быть я застрелю зевчонкв? ==> Можте быть я застрелю девчонку? !!!=== Может быть я застрелю девчонку?\n",
      "FAILED ||  Ты хочешь, чтобы я огриабла собственный дм? ==> Ты хочешь, чтобы я ограбила собственный ты? !!!=== Ты хочешь, чтобы я ограбила собственный дом?\n",
      "FAILED ||  Блужа Эстель размер цвео черный ==> Блузка Эстель размер цвет черный !!!=== Блуза Эстель размер цвет черный\n",
      "FAILED ||  Брось, я нзал! ==> Брось, я знаю! !!!=== Брось, я знал!\n",
      "FAILED ||  Меня он давым-дано не оценивал. ==> Меня он давай-дано не оценивал. !!!=== Меня он давным-давно не оценивал.\n",
      "FAILED ||  Пожалуйста, зов меня Лекс. ==> Пожалуйста, зов меня Лекс. !!!=== Пожалуйста, зовите меня Лекс.\n",
      "FAILED ||  Карев, держи около висков И нежео пaднмиай ==> Карев, держи около висков И нежное поднимай !!!=== Карев, держи около висков И нежно поднимай\n",
      "FAILED ||  Корюшка сялен Ассорти Плюс ==> Корюшка пятен Ассорти Плюс !!!=== Корюшка вяленая Ассорти Плюс\n",
      "FAILED ||  Вы получаете все, что-- Обычная реклап. ==> Вы получаете все, что-- Обычная реклама. !!!=== Вы получаете всё, что-- Обычная реклама.\n",
      "FAILED ||  Хамса мороженная кофрощяик ==> Хамса мороженная гофроящик !!!=== Хамса мороженная гофроящике\n",
      "FAILED ||  Тут не за чт ухватиться. ==> Тут не за чт ухватиться. !!!=== Тут не за что ухватиться.\n",
      "FAILED ||  - Нет, не над. Игги, я должн пойти. ==> - Нет, не над. Игги, я должн пойти. !!!=== - Нет, не надо. Игги, я должен пойти.\n",
      "FAILED ||  Фирменный набр прниадлежр персона ==> Фирменный набр принадлежу персона !!!=== Фирменный набор принадлежностей персона\n",
      "FAILED ||  Корж вафелн Минутка ==> Корж вафельн Минутка !!!=== Корж вафельный Минутка\n",
      "FAILED ||  двадца третий, где твой ремеь? ==> двадцать третий, где твой ремень? !!!=== Двадцать третий, где твой ремень?\n",
      "FAILED ||  Флуцинар мать Jellfa Польша ==> Флуцинар мать Jellfa Польша !!!=== Флуцинар мазь Jellfa Польша\n",
      "FAILED ||  чкаж, когда остюда уходит почта в Шанхай? ==> этаж, когда остюда уходит почта в Шанхай? !!!=== Скажите, когда отсюда уходит почта в Шанхай?\n",
      "FAILED ||  - Я его кюда-то засунул. ==> - Я его кюда-то засунул. !!!=== - Я его куда-то засунул.\n",
      "FAILED ||  Пaслушафтк, у нас ест только неделя. ==> Пaслушафтк, у нас ест только неделя. !!!=== Послушайте, у нас есть только неделя.\n",
      "FAILED ||  Ты ни в чм не видишь плюс, ==> Ты ни в чм не видишь плюс, !!!=== Ты ни в чём не видишь плюс,\n",
      "FAILED ||  - Это бл ьтличны вечер. - Потрясающий вечер. ==> - Это бл отличный вечер. - Потрясающий вечер. !!!=== - Это был отличный вечер. - Потрясающий вечер.\n",
      "FAILED ||  У нее быб только эар. Я не понял. ==> У нее было только это. Я не понял. !!!=== У нее был только жар. Я не понял.\n",
      "FAILED ||  Ну оак, они назначили теб курьером, а? ==> Ну оак, они назначили теб курьером, а? !!!=== Ну так, они назначили тебя курьером, а?\n",
      "FAILED ||  И я такая, кк ты говорил. ==> И я такая, не ты говорил. !!!=== И я такая, как ты говорил.\n",
      "FAILED ||  Ты эоого хочешь? Я так и дума. ==> Ты этого хочешь? Я так и дума. !!!=== Ты этого хочешь? Я так и думала.\n",
      "FAILED ||  - Хэнук я давала. ==> - Хануку я давала. !!!=== - Хэнку я давала.\n",
      "FAILED ||  - Отбросьте тэо! - Наденьте это! ==> - Отбросьте тэо! - Наденьте это! !!!=== - Отбросьте это! - Наденьте это!\n",
      "FAILED ||  Капуста белокочанная реазнмя Белая зача Бела ==> Капуста белокочанная резаная Белая мама Бела !!!=== Капуста белокочанная резаная Белая дача Бела\n",
      "FAILED ||  О! Снова оео! ==> О! Снова это! !!!=== О! Снова оно!\n",
      "FAILED ||  Зачем вам этп, прости гсоподе, груда желпза? ==> Зачем вам этот, прости господи, груда железа? !!!=== Зачем вам эта, прости господи, груда железа?\n",
      "FAILED ||  Да ладно. И кае же вы .то сделаете? ==> Да ладно. И как же вы .то сделаете? !!!=== Да ладно. И как же вы это сделаете?\n",
      "FAILED ||  Медицинская арта ребенк ==> Медицинская арта ребенк !!!=== Медицинская карта ребенк\n",
      "FAILED ||  Ты забыл, Джеральд, чот ты уже не начабьниа цеха. ==> Ты забыл, Джеральд, чот ты уже не начальник цеха. !!!=== Ты забыл, Джеральд, что ты уже не начальник цеха.\n",
      "FAILED ||  Позвольте ысразить сам мое сочувствие. ==> Позвольте выразить сам мое сочувствие. !!!=== Позвольте выразить вам мое сочувствие.\n",
      "FAILED ||  Махги это пиво дла равновесия. ==> Мозги это пиво для равновесия. !!!=== Махни это пиво для равновесия.\n",
      "FAILED ||  Не снимай руку с это кнопи. ==> Не снимай руку с это кнопки. !!!=== Не снимай руку с этой кнопки.\n",
      "FAILED ||  - вытиарт ты будешь. ==> - вытирать ты будешь. !!!=== - Вытирать ты будешь.\n",
      "FAILED ||  Мне бы не хотел еорпуст твой финал! ==> Мне бы не хотел корпусу твой финал! !!!=== Мне бы не хотелось пропустить твой финал!\n",
      "FAILED ||  Ч ј тэо сто? ѕочему это не моЄ? ѕочему это не моЄ? ==> Ч ј тэо сто? ѕочему это не моЄ? ѕочему это не моЄ? !!!=== Ч ј это что? ѕочему это не моЄ? ѕочему это не моЄ?\n",
      "FAILED ||  Не важнa. Просто, чтобы ухать. ==> Не важно. Просто, чтобы ухать. !!!=== Не важно. Просто, чтобы уехать.\n",
      "FAILED ||  Купи мне вып и абудеп об этом. ==> Купи мне всё и забудем об этом. !!!=== Купи мне выпить и забудем об этом.\n",
      "FAILED ||  Круассаны Chipicao брем какао ==> Круассаны Chipicao брем какао !!!=== Круассаны Chipicao крем какао\n",
      "FAILED ||  Почти феодализм, ебат. ==> Почти феодализм, брат. !!!=== Почти феодализм, ебать.\n",
      "FAILED ||  Пара, аммочк умерла давным-давно. ==> Пара, мамочка умерла давным-давно. !!!=== Папа, мамочка умерла давным-давно.\n",
      "FAILED ||  Текущий ремонт пеин ==> Текущий ремонт грин !!!=== Текущий ремонт пени\n",
      "FAILED ||  Это - икпя масло. ==> Это - дикая масло. !!!=== Это - кипящее масло.\n",
      "FAILED ||  Доброе уто, Пери ==> Доброе что, Пери !!!=== Доброе утро, Пери\n",
      "FAILED ||  В сумрак без мнея не входить. пaнятн? Ну... ==> В сумрак без мнея не входить. понятно? Ну... !!!=== В сумрак без меня не входить. Понятно? Ну...\n",
      "FAILED ||  В общем, мы цел день проторчали в разынх банках. ==> В общем, мы цел день проторчали в разных банках. !!!=== В общем, мы целый день проторчали в разных банках.\n",
      "FAILED ||  Тупая,.. ьяная... сука! ==> Тупая,.. мясная... сука! !!!=== Тупая,.. пьяная... сука!\n",
      "FAILED ||  Фасоль зелпрая сезона ==> Фасоль зелёная сезона !!!=== Фасоль зеленая сезона\n",
      "FAILED ||  рПеурасно, реальные основания, зорошо. ==> прекрасно, реальные основания, хорошо. !!!=== Прекрасно, реальные основания, хорошо.\n",
      "FAILED ||  мреднление мастита скрытой форм ==> мреднление мастита скрытой форм !!!=== Определение мастита скрытой формы\n",
      "FAILED ||  Вы забыои ону вещь. Меня. ==> Вы забери мне вещь. Меня. !!!=== Вы забыли одну вещь. Меня.\n",
      "FAILED ||  Арахис жаренный укусик ==> Арахис жаренный укусов !!!=== Арахис жаренный кукусики\n",
      "FAILED ||  Предоставление одн стреловвоо места тире ==> Предоставление один стреловвоо места тире !!!=== Предоставление одного стрелкового места тире\n",
      "FAILED ||  - Какя же ты упрямая и твердолобая. ==> - Какя же ты упрямая и твердолобая. !!!=== - Какая же ты упрямая и твердолобая.\n",
      "FAILED ||  эт не пмеет отношения к тебе или ко всему этомв. ==> эт не имеет отношения к тебе или ко всему этому. !!!=== Это не имеет отношения к тебе или ко всему этому.\n",
      "FAILED ||  Оке, $ 2 останется, и потрачено $ 18. ==> Оке, $ 2 останется, и потрачено $ 18. !!!=== Окей, $ 2 останется, и потрачено $ 18.\n",
      "FAILED ||  Котлеты Нежные Русский морощ ==> Котлеты Нежные Русский горох !!!=== Котлеты Нежные Русский мороз\n",
      "FAILED ||  Kрышка расширит баска ==> Kрышка расширит паста !!!=== Kрышка расширит бачка\n",
      "FAILED ||  Моч сестра шпионит за мной, но это нормбаьно. ==> Мой сестра шпионит за мной, но это нормально. !!!=== Моя сестра шпионит за мной, но это нормально.\n",
      "FAILED ||  Леска Tiagra ассорримтее ==> Леска Tiagra ассортимете !!!=== Леска Tiagra ассортименте\n",
      "FAILED ||  Похьже на чудовище. ==> Похожа на чудовище. !!!=== Похоже на чудовище.\n",
      "FAILED ||  Надеюсь, ты не прот сесть назад. ==> Надеюсь, ты не прот сесть назад. !!!=== Надеюсь, ты не против сесть назад.\n",
      "TOTAL ACU:  0.49\n",
      "SECONDS PER ITER : 0.1937\n",
      "TOTAL HOURS FOR ALL PRiVATE:  3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:38<00:00,  5.16it/s]\n"
     ]
    }
   ],
   "source": [
    "#!g2.mig\n",
    "data_val = data[0:200]\n",
    "validate(data_val, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "7twrpm8622d4wkfcqyvauv",
    "execution_id": "a9916f3e-cd97-4aa1-a5d5-cb85a53c863c"
   },
   "source": [
    "# Private submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "cellId": "jmyz3aei3ejlr0ubcfc92"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "data_sub = pd.read_csv(\"./private_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "cellId": "lnwu38xf3re9mirwd4oq4g"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corrupted_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>мясыне блюда говядина</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- А можно я пойд?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Бордюры обонй ассортименте</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Вместо союса кетчуп</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Не прдесталя, как она могла туда папаст.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             corrupted_text\n",
       "0                     мясыне блюда говядина\n",
       "1                         - А можно я пойд?\n",
       "2                Бордюры обонй ассортименте\n",
       "3                       Вместо союса кетчуп\n",
       "4  Не прдесталя, как она могла туда папаст."
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.mig\n",
    "data_sub.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "cellId": "h7cry1pwrjb2mt25sd8xmt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56526"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g2.mig\n",
    "len(data_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "cellId": "2phr4nectc2bleaa2v4i8d"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "def submit(data, outpath):\n",
    "    with open(outpath, 'w') as file:\n",
    "        for i, elm in tqdm(enumerate(data.corrupted_text), total = len(data)):\n",
    "            file.write(find_best(elm) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "cellId": "mwrex231794r9qomg8968"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56526/56526 [3:37:05<00:00,  4.34it/s]\n"
     ]
    }
   ],
   "source": [
    "#!g2.mig\n",
    "submit(data_sub, \"private.submit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "cellId": "a66ck4efuylnoayes0ucz"
   },
   "outputs": [],
   "source": [
    "#!g2.mig\n",
    "with open(\"private.submit\") as file:\n",
    "    file.read().split(\"n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "794f1aa6-676a-451a-a2bd-4e9c3eb36daa",
  "notebookPath": "rucodeB/rucodeB.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
